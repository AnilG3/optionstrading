{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a0ace07-885d-4a4b-86f7-ffd9af07e2a4",
   "metadata": {},
   "source": [
    "#### Download Stock and Option Price Data for Group of Securities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e18ca0e-db9e-42a3-9627-73a242521a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, date\n",
    "\n",
    "import pandas_datareader.data as web\n",
    "from pandas_datareader.yahoo.headers import DEFAULT_HEADERS\n",
    "\n",
    "import requests\n",
    "from time import sleep\n",
    "\n",
    "import yfinance as yf # for minute data, https://github.com/ranaroussi/yfinance\n",
    "\n",
    "from threading import Thread\n",
    "from itertools import islice\n",
    "\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f95d63be-622a-4a00-a799-15826b0d64a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions to retrieve Stock Price and Options Data\n",
    "\n",
    "# Get daily stock price data using Pandas Datareader from Yahoo! Finance\n",
    "def get_stock_price_using_pdr(security, period=1):\n",
    "    # security = Ticker symbol of stock, string ex: 'TQQQ'\n",
    "    # period = Years of data to reterive, integer ex: 1 for 1 year\n",
    "    session = requests.Session()\n",
    "    session.headers = DEFAULT_HEADERS\n",
    "\n",
    "    source = 'yahoo' # Source of data\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date.replace(year = end_date.year - period)\n",
    "        \n",
    "    df = web.DataReader(security, source, start_date, end_date, session=session)\n",
    "    df = df.sort_values(by='Date')\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Save to CSV file\n",
    "    file_name = 'data/{}_daily_{}.csv'.format(security, df.index[-1].strftime('%Y%m%d'))\n",
    "    df.to_csv(file_name)\n",
    "    #print('{} stock {} year daily price data downloaded.'.format(security, period))\n",
    "    \n",
    "    return file_name\n",
    "\n",
    "# Get minute level stock price data using yfinance\n",
    "def get_stock_price_data_using_yf(security, period='1mo', interval='2m'):\n",
    "    # security = Ticker symbol, string ex: 'AAPL'\n",
    "    # period = Months/Days of data to retrieve, string ex: '1mo' for 1 month\n",
    "    # interval = Interval between price data, string ex: '2m' for 2 minute\n",
    "            \n",
    "    df = yf.Ticker(security).history(period=period, interval=interval, \\\n",
    "                                           actions=False, auto_adjust=False)\n",
    "    df = df.sort_values(by='Datetime')\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Save to CSV file\n",
    "    file_name = 'data/{}_{}_{}.csv'.format(security, interval, \\\n",
    "                                           df.index[-1].strftime('%Y%m%d%H%M%S'))\n",
    "    df.to_csv(file_name)\n",
    "    #print('{} stock {} month {} price data downloaded.'.format(security, period, interval))\n",
    "\n",
    "    return file_name\n",
    "\n",
    "# Get Option Data using pandas datareader\n",
    "def get_options_data_using_pdr(security):\n",
    "    # Retrieve Options Data from Yahoo! Finance\n",
    "    session = requests.Session()\n",
    "    session.headers = DEFAULT_HEADERS\n",
    "\n",
    "    options = web.YahooOptions(security, session=session)\n",
    "    df = options.get_all_data()\n",
    "\n",
    "    # Flatten the option pricing df and save as CSV\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # find the latest Quote time\n",
    "    latest_quote = df.Quote_Time.max()\n",
    "        \n",
    "    # Save to CSV file\n",
    "    file_name = 'data/{}_options_{}.csv'.format(security, latest_quote.strftime('%Y%m%d'))\n",
    "    df.to_csv(file_name, index=False)\n",
    "    #print('{} option data downloaded.'.format(security))\n",
    "    \n",
    "    return file_name\n",
    "\n",
    "# Get Historical Corporate Actions using pandas datareader\n",
    "def get_actions_using_pdr(security):\n",
    "    # Retrieve Historical Corporate Actions from Yahoo! Finance\n",
    "    actions = web.DataReader(security, 'yahoo-actions')\n",
    "    \n",
    "    if (actions.empty != True):\n",
    "        # Save to CSV file\n",
    "        file_name = 'data/{}_actions.csv'.format(security)\n",
    "        actions.to_csv(file_name)\n",
    "        #print('{} corporate actions data downloaded.'.format(security))\n",
    "\n",
    "        return file_name\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Get Next Corporate Activity using yfinance\n",
    "def get_calendar_using_yf(security):\n",
    "    x = yf.Ticker(security)\n",
    "    \n",
    "    calendar = x.calendar\n",
    "    \n",
    "    if (calendar is not None):\n",
    "        # Save to CSV file\n",
    "        file_name = 'data/{}_calendar.csv'.format(security)\n",
    "        calendar.to_csv(file_name)\n",
    "        #print('{} calendar data downloaded'.format(security))\n",
    "        \n",
    "        return file_name\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# Get Historical Earnings using yfinance\n",
    "def get_earnings_hist_using_yf(security):\n",
    "    x = yf.Ticker(security)\n",
    "    \n",
    "    earnings_hist = x.earnings_dates\n",
    "    \n",
    "    if (earnings_hist.empty != True):\n",
    "        # Save to CSV file\n",
    "        file_name = 'data/{}_earnings_hist.csv'.format(security)\n",
    "        earnings_hist.to_csv(file_name)\n",
    "        #print('{} earnings history data downloaded'.format(security))\n",
    "    \n",
    "        return file_name\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# Get Historical Earnings and price change from Earnings from TipRanks\n",
    "def get_earnings_hist_from_tipranks(security):\n",
    "    \n",
    "    try:\n",
    "        # Get Earnings data for specific security from TipRanks\n",
    "\n",
    "        url = 'https://www.tipranks.com/stocks/{}/earnings'\n",
    "        header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'}\n",
    "\n",
    "        r = requests.get(url.format(security), headers=header)\n",
    "\n",
    "\n",
    "        # Eaxtract data from Earnings History table\n",
    "        eps_hist_df = pd.read_html(r.content, match=\"EPS YoY Change\", index_col=None, parse_dates=True)\n",
    "        eps_hist_df = eps_hist_df[0]\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'report_date': pd.to_datetime(eps_hist_df['Report Date']), \n",
    "            'eps_prev_yr': eps_hist_df[\"Last Year's EPS\"]\n",
    "        })\n",
    "\n",
    "        df = df.join([\n",
    "            eps_hist_df['Fiscal Quarter'].str.split(' ', expand=True).rename(columns={0: 'fiscal_yr', 1: 'fiscal_qtr'}),\n",
    "            eps_hist_df['Forecast / EPS'].str.split('/', expand=True).rename(columns={0: 'eps_forecast', 1: 'eps_actual'}),\n",
    "            eps_hist_df['EPS YoY Change'].str.split('% ', expand=True).rename(columns={0: 'eps_yoy_pct', 1: 'eps_yoy_chg'})\n",
    "        ])\n",
    "\n",
    "        df['fiscal_qtr'] = df['fiscal_qtr'].str[2:3]\n",
    "        df['eps_yoy_chg'] = df['eps_yoy_chg'].str[1:-1]\n",
    "\n",
    "        columns=['report_date', 'fiscal_yr', 'fiscal_qtr', 'eps_forecast', 'eps_actual', 'eps_prev_yr', 'eps_yoy_chg', 'eps_yoy_pct']\n",
    "\n",
    "        df = df.reindex(columns=columns)\n",
    "\n",
    "        # Extract data from Price Change table\n",
    "        price_change_df = pd.read_html(r.content, match=\"Price 1 Day Before\", index_col=None, parse_dates=True)\n",
    "        price_change_df = price_change_df[0]\n",
    "\n",
    "        df1 = pd.DataFrame({\n",
    "            'report_date': pd.to_datetime(price_change_df['Report Date']), \n",
    "            'price_1d_before': price_change_df['Price 1 Day Before'].str[1:], \n",
    "            'price_1d_after': price_change_df['Price 1 Day After'].str[1:],\n",
    "            'price_pct_change': price_change_df['Percentage Change'].str[:-1]\n",
    "        })\n",
    "\n",
    "        # Merge past earnings df and price change due to earnings df\n",
    "        df2 = df.merge(df1, on='report_date', how='left')\n",
    "\n",
    "        # Change columns data type\n",
    "        cols = df2.select_dtypes(include=['object']).columns\n",
    "        df2[cols] = df2[cols].apply(pd.to_numeric, errors='coerce')\n",
    "        #display(df2)\n",
    "    except:\n",
    "        df2 = None\n",
    "    \n",
    "    if (df2.empty != True):\n",
    "        # Save to CSV file\n",
    "        file_name = 'data/{}_earnings_hist_tipranks.csv'.format(security)\n",
    "        df2.to_csv(file_name)\n",
    "        #print('{} TipRanks earnings history data downloaded'.format(security))\n",
    "    \n",
    "        return file_name\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0a33cfb-bb7c-466a-8e34-ed616d0eb097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group of Securities\n",
    "\n",
    "# portfolio holdings\n",
    "etf_holdings = ['TQQQ', 'UPRO']\n",
    "stock_holdings = ['META', 'AAPL', 'PLTR', 'GPRO', 'C']\n",
    "\n",
    "# trades executed with year\n",
    "etf_trades = ['TLT', 'SOXL', 'SQQQ', 'DIA', 'USO']\n",
    "stock_trades = ['DOW', 'NKE', 'WMT', 'TWTR', 'MRK', 'XOM', 'PYPL', 'AMC', 'RBLX', 'DIS', 'SE', 'HD', \\\n",
    "                'M', 'PANW', 'ZM', 'SNOW', 'CRM', 'NVDA', 'CHPT', 'OKTA', 'BTU', 'MSFT', 'AMZN', 'GOOGL', \\\n",
    "                'GME', 'AEO', 'DOCU', 'KR', 'PINS', 'NIO', 'ABNB', 'DVN', 'ADP', 'AXP', 'BX', 'CGC', 'CLOV', \\\n",
    "                'CMCSA', 'LMT', 'RKT', 'SOFI', 'UNH', 'BIIB', 'CI', 'COST', 'TSLA']\n",
    "\n",
    "# index etfs for tracking\n",
    "index_etfs = ['SPY', 'QQQ', 'IWM', 'LQD', 'UVXY', 'VXX']\n",
    "\n",
    "# new etfs and stocks under consideration\n",
    "new_etfs = ['XBI', 'XLK', 'XLY', 'XLF', 'XLE', 'XOP', 'ARKK', 'TBT', 'ARKG', 'SMH']\n",
    "new_stocks = ['BABA', 'INTC', 'AMD', 'T', 'V', 'SBUX', 'UBER']\n",
    "\n",
    "# potential earnings play\n",
    "earning_stocks = ['RAD', 'NKE', 'MU', 'CCL', 'STZ', 'CAG', 'LEVI', 'AEHR', 'TLRY']\n",
    "\n",
    "# etf_list is used to filter earnings report from TipRanks\n",
    "etf_list = etf_holdings + etf_trades + index_etfs + new_etfs\n",
    "\n",
    "master_list = etf_holdings + stock_holdings + etf_trades + stock_trades + index_etfs + new_stocks + new_etfs + earning_stocks\n",
    "\n",
    "# remove duplicates while keeping order\n",
    "master_list = sorted(set(master_list), key=master_list.index)\n",
    "\n",
    "# Exclude tickers (low open interest, low price)\n",
    "#excluded_tickers = ['ADP', 'LMT', 'UNH']\n",
    "excluded_tickers = []\n",
    "\n",
    "securities = [ticker for ticker in master_list if ticker not in excluded_tickers]\n",
    "\n",
    "# PmTraders lotto (Not included in primary download; download separately)\n",
    "lotto_stocks = ['AA', 'ABC', 'ABNB', 'ABT', 'ACHC', 'ACN', 'ADBE', 'ADP', 'ADSK', 'AFL', 'ALB', 'ALGN', 'AMBA', 'AMD', 'AMG', 'AMGN', 'ANET', 'APA', 'APO', 'ASML', \\\n",
    "                'AXON', 'AXP', 'AZO', 'BIIB', 'BILL', 'BLK', 'BNTX', 'BUD', 'BURL', 'BX', 'CAT', 'CCI', 'CF', 'CHTR', \\\n",
    "                'CI', 'CLX', 'CMG', 'COUP', 'CTAS', 'CTRA', 'CVNA', 'CZR', 'DE', 'DFS', 'DHI', 'DIOD', 'DKS', 'DOCU', 'DPZ', 'DUOL', 'EL', \\\n",
    "                'ENPH', 'EOG', 'EXPE', 'EW', 'FCX', 'FFIV', 'FIVE', 'FSLR', 'GD', 'GFS', 'GS', \\\n",
    "                'HES', 'HP', 'HSY', 'HUBB', 'HUBS', 'ILMN', 'INTU', 'IR', 'ISRG', 'ITW', 'JBHT', \\\n",
    "                'KKR', 'KLAC', 'LEN', 'LHX', 'LIN', 'LLY', 'LMT', 'LNG', 'MA', 'MAR', 'MCK', 'MDB', 'MELI', 'MOS', \\\n",
    "                'MPC', 'NDSN', 'NET', 'NFLX', 'NOW', 'NSC', 'NTR', 'OIH', 'OKTA', 'OLED', 'OLN', 'ON', 'PANW', 'PEP', 'PM', \\\n",
    "                'PNC', 'PPG', 'PSX', 'PXD', 'RACE', 'RCL', 'REGN', 'RH', 'ROKU', 'ROST', 'RRC', 'SLB', 'SNOW', 'SPGI', 'SPLK', 'SPOT', \\\n",
    "                'SPT', 'SQM', 'SWKS', 'SYF', 'SYK', 'TEAM', 'TELL', 'TM', 'TMO', 'TNDM', 'TOL', \\\n",
    "                'TSCO', 'TTD', 'TTWO', 'TWLO', 'U', 'UFCS', 'ULTA', 'UNP', 'URI', 'USO', 'VAC', 'VFC', 'VLO', 'VRTX', \\\n",
    "                'W', 'WDAY', 'WDC', 'WHR', 'WM', 'WYNN', 'XHB', 'ZBH', 'ZS']\n",
    "\n",
    "# debug\n",
    "#securities = set(['C'])\n",
    "#securities = set(earning_stocks)\n",
    "# securities = set(lotto_stocks)\n",
    "\n",
    "# new tickers that are not in previous lists for download\n",
    "#securities = set(master_list + lotto_stocks)\n",
    "#securities = set([ticker for ticker in lotto_stocks if ticker not in master_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bb0c3ba-1298-4851-b87a-95ad4cebc97c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_data(tlist):\n",
    "    data = []\n",
    "    downloaded_tickers = []\n",
    "    troubled_tickers = []\n",
    "\n",
    "    # [NOTE]: Randomizing list wasn't effective.\n",
    "    # Yahoo! seems to send incomplete data after a while.\n",
    "    # Put important tickers first.\n",
    "    #shuffle(securities)\n",
    "\n",
    "    print('Data for {} securities to be downloaded'.format(len(tlist)))\n",
    "\n",
    "    for t in tlist:\n",
    "        # The download for this section must be clean and complete\n",
    "        # Redownload incomplete downloaded securities\n",
    "        try:\n",
    "            # daily price data\n",
    "            data.append([t, 'daily', get_stock_price_using_pdr(t)])\n",
    "\n",
    "            # 2 minute price data\n",
    "            data.append([t, '2min', get_stock_price_data_using_yf(t, period='1mo', interval='2m')])\n",
    "\n",
    "            # Option data\n",
    "            data.append([t, 'option', get_options_data_using_pdr(t)])\n",
    "\n",
    "            # Add to list of downloded tickers\n",
    "            downloaded_tickers.append(t)\n",
    "\n",
    "            # sleep randomly\n",
    "            #sleep(np.random.uniform(1,2))\n",
    "        except:\n",
    "            print('Download incomplete for: {}'.format(t))\n",
    "            troubled_tickers.append(t)\n",
    "\n",
    "    # Successful and incomplete download info\n",
    "    print('Data Download Incomplete for {}: {}'.format(len(troubled_tickers), troubled_tickers))\n",
    "    print('Data Download Successful for {}: {}'.format(len(downloaded_tickers), downloaded_tickers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52ef901a-f099-4c6c-9c5c-001fc9be8e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download Tipranks earnings data separately\n",
    "def download_tipranks_earning(tlist):\n",
    "    data = []\n",
    "    troubled_tickers = []\n",
    "\n",
    "    for t in tlist:\n",
    "        try:\n",
    "            if t not in etf_list:\n",
    "                # TipRanks Earnings history\n",
    "                data.append([t, 'tipranks_earning_hist', get_earnings_hist_from_tipranks(t)])\n",
    "        except:\n",
    "            troubled_tickers.append(t)\n",
    "            pass\n",
    "\n",
    "    print('Tipranks Earnings Incomplete for {}: {}'.format(len(troubled_tickers), troubled_tickers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cf774fd-c504-474f-aafe-8d00e14cc1e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download Yahoo earnings history data separately\n",
    "def download_earning_hist(tlist):\n",
    "    data = []\n",
    "    troubled_tickers = []\n",
    "\n",
    "    for t in tlist:\n",
    "\n",
    "        try:\n",
    "            if t not in etf_list:\n",
    "                # Earnings history\n",
    "                data.append([t, 'earning_hist', get_earnings_hist_using_yf(t)])\n",
    "\n",
    "        except:\n",
    "            troubled_tickers.append(t)\n",
    "            pass\n",
    "    \n",
    "\n",
    "    print('Earning Hist Incomplete for {}: {}'.format(len(troubled_tickers), troubled_tickers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0829f923-9c25-4e63-9221-56e227cd0c14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Corporate Action data download\n",
    "def download_corpaction(tlist):\n",
    "    data = []\n",
    "    troubled_tickers = []\n",
    "\n",
    "    for t in tlist:\n",
    "\n",
    "        try:\n",
    "            # Corporate Action data\n",
    "            data.append([t, 'corp_action', get_actions_using_pdr(t)])\n",
    "\n",
    "        except:\n",
    "            troubled_tickers.append(t)\n",
    "            pass\n",
    "\n",
    "\n",
    "    print('CorpAction Incomplete for {}: {}'.format(len(troubled_tickers), troubled_tickers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f05bccde-3d6a-45e4-940d-e37476d3c462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download Yahoo earnings calendar data\n",
    "def download_calendar(tlist):\n",
    "    data = []\n",
    "    troubled_tickers = []\n",
    "\n",
    "    for t in tlist:\n",
    "    \n",
    "        try:\n",
    "            if t not in etf_list:\n",
    "                # Calendar data\n",
    "                data.append([t, 'calendar', get_calendar_using_yf(t)])\n",
    "\n",
    "        except:\n",
    "            troubled_tickers.append(t)\n",
    "            pass\n",
    "        \n",
    "    print('Calendar incomplete for {}: {}'.format(len(troubled_tickers), troubled_tickers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75a68727-6695-4abd-ab06-e73aacfda8b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split list of secrities in smaller chunks for processing\n",
    "def grouper(n, iterable):\n",
    "    \n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        chunk = tuple(islice(it, n))\n",
    "        if not chunk:\n",
    "            return\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e992f51-4552-42f3-a525-927b338270f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process(tlist):\n",
    "        \n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    \n",
    "    download_data(tlist)\n",
    "    download_tipranks_earning(tlist)\n",
    "    download_earning_hist(tlist)\n",
    "    download_corpaction(tlist)\n",
    "    download_calendar(tlist)\n",
    "    \n",
    "    print(tlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d57c7ad9-b682-4fe5-9c9c-142e4dc8825d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(securities):\n",
    "    \n",
    "    splits = grouper(10, securities)\n",
    "    \n",
    "    for array in splits:\n",
    "        process_thread = Thread(target=process, args=(array,))\n",
    "        process_thread.start()\n",
    "        # sleep randomly\n",
    "        sleep(np.random.uniform(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7738d45b-b4c0-4e83-8f3b-e34629128ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 20 securities to be downloaded\n",
      "Data for 20 securities to be downloaded\n",
      "Data for 20 securities to be downloadedData for 20 securities to be downloadedData for 20 securities to be downloaded\n",
      "\n",
      "\n",
      "Data for 20 securities to be downloadedData for 20 securities to be downloaded\n",
      "\n",
      "Data for 20 securities to be downloaded\n",
      "Data for 20 securities to be downloadedData for 20 securities to be downloadedData for 20 securities to be downloaded\n",
      "\n",
      "\n",
      "Data for 10 securities to be downloaded\n",
      "Data Download Incomplete for 0: []\n",
      "Data Download Successful for 10: ['W', 'CAG', 'CLOV', 'SMH', 'JBHT', 'EW', 'APA', 'MELI', 'ASML', 'FCX']\n",
      "('W', 'CAG', 'CLOV', 'SMH', 'JBHT', 'EW', 'APA', 'MELI', 'ASML', 'FCX')\n",
      "Data Download Incomplete for 0: []\n",
      "Data Download Successful for 20: ['TBT', 'NG', 'COUP', 'CTRA', 'AA', 'ARKG', 'XBI', 'UPRO', 'DKS', 'KR', 'NTR', 'KLAC', 'MAR', 'RAD', 'TWTR', 'ACHC', 'CTAS', 'AXP', 'NIO', 'PM']\n",
      "('TBT', 'NG', 'COUP', 'CTRA', 'AA', 'ARKG', 'XBI', 'UPRO', 'DKS', 'KR', 'NTR', 'KLAC', 'MAR', 'RAD', 'TWTR', 'ACHC', 'CTAS', 'AXP', 'NIO', 'PM')\n",
      "Data Download Incomplete for 0: []\n",
      "Data Download Successful for 20: ['CI', 'SPGI', 'LMT', 'SE', 'VAC', 'SOFI', 'ADP', 'SPOT', 'DE', 'TLRY', 'ABT', 'AZO', 'ISRG', 'MCK', 'LQD', 'PNC', 'CVNA', 'VFC', 'FFIV', 'LIN']\n",
      "('CI', 'SPGI', 'LMT', 'SE', 'VAC', 'SOFI', 'ADP', 'SPOT', 'DE', 'TLRY', 'ABT', 'AZO', 'ISRG', 'MCK', 'LQD', 'PNC', 'CVNA', 'VFC', 'FFIV', 'LIN')\n",
      "Data Download Incomplete for 0: []\n",
      "Data Download Successful for 20: ['NFLX', 'WYNN', 'MOS', 'ROKU', 'CMG', 'LEN', 'XLY', 'DFS', 'HSY', 'UFCS', 'DIOD', 'ZM', 'ADBE', 'MDB', 'TSCO', 'WMT', 'OKTA', 'TMO', 'ENPH', 'TTD']\n",
      "('NFLX', 'WYNN', 'MOS', 'ROKU', 'CMG', 'LEN', 'XLY', 'DFS', 'HSY', 'UFCS', 'DIOD', 'ZM', 'ADBE', 'MDB', 'TSCO', 'WMT', 'OKTA', 'TMO', 'ENPH', 'TTD')\n",
      "Data Download Incomplete for 0: []\n",
      "Data Download Successful for 20: ['LHX', 'GS', 'MA', 'CF', 'SBUX', 'AXON', 'CHTR', 'ABC', 'FIVE', 'AMZN', 'ITW', 'SYK', 'BUD', 'UVXY', 'U', 'PPG', 'ALGN', 'OLN', 'RBLX', 'SQM']\n",
      "('LHX', 'GS', 'MA', 'CF', 'SBUX', 'AXON', 'CHTR', 'ABC', 'FIVE', 'AMZN', 'ITW', 'SYK', 'BUD', 'UVXY', 'U', 'PPG', 'ALGN', 'OLN', 'RBLX', 'SQM')\n",
      "Data Download Incomplete for 0: []\n",
      "Data Download Successful for 20: ['INTC', 'AEHR', 'NVDA', 'DHI', 'URI', 'XLF', 'HUBB', 'LEVI', 'REGN', 'WDAY', 'WM', 'CRM', 'ROST', 'HD', 'M', 'XOP', 'DVN', 'MRK', 'PLTR', 'TELL']\n",
      "('INTC', 'AEHR', 'NVDA', 'DHI', 'URI', 'XLF', 'HUBB', 'LEVI', 'REGN', 'WDAY', 'WM', 'CRM', 'ROST', 'HD', 'M', 'XOP', 'DVN', 'MRK', 'PLTR', 'TELL')\n",
      "Data Download Incomplete for 0: []\n",
      "Data Download Successful for 20: ['RH', 'EL', 'USO', 'NKE', 'DPZ', 'RCL', 'GME', 'SWKS', 'COST', 'CMCSA', 'META', 'FDX', 'DUOL', 'TQQQ', 'IR', 'NOW', 'GFS', 'HES', 'CHPT', 'RACE']\n",
      "('RH', 'EL', 'USO', 'NKE', 'DPZ', 'RCL', 'GME', 'SWKS', 'COST', 'CMCSA', 'META', 'FDX', 'DUOL', 'TQQQ', 'IR', 'NOW', 'GFS', 'HES', 'CHPT', 'RACE')\n",
      "Data Download Incomplete for 0: []\n",
      "Data Download Successful for 20: ['TTWO', 'ON', 'UNH', 'NSC', 'ANET', 'RRC', 'MPC', 'BX', 'MU', 'HP', 'VRTX', 'AMC', 'LLY', 'EXPE', 'GOOGL', 'CGC', 'WHR', 'PSX', 'STZ', 'DOW']\n",
      "('TTWO', 'ON', 'UNH', 'NSC', 'ANET', 'RRC', 'MPC', 'BX', 'MU', 'HP', 'VRTX', 'AMC', 'LLY', 'EXPE', 'GOOGL', 'CGC', 'WHR', 'PSX', 'STZ', 'DOW')\n",
      "Data Download Incomplete for 0: []\n",
      "Data Download Successful for 20: ['T', 'ZS', 'XLK', 'NET', 'TLT', 'PANW', 'SYF', 'DIS', 'HUBS', 'CZR', 'EOG', 'GPRO', 'SNOW', 'SPY', 'NDSN', 'SPT', 'PXD', 'TWLO', 'ULTA', 'KKR']\n",
      "('T', 'ZS', 'XLK', 'NET', 'TLT', 'PANW', 'SYF', 'DIS', 'HUBS', 'CZR', 'EOG', 'GPRO', 'SNOW', 'SPY', 'NDSN', 'SPT', 'PXD', 'TWLO', 'ULTA', 'KKR')\n",
      "Data Download Incomplete for 0: []\n",
      "Data Download Successful for 20: ['SPLK', 'MSFT', 'AMGN', 'BILL', 'OLED', 'PEP', 'BTU', 'AEO', 'AMBA', 'C', 'XHB', 'AMG', 'IWM', 'ARKK', 'WDC', 'LNG', 'XOM', 'TEAM', 'UBER', 'CCI']\n",
      "('SPLK', 'MSFT', 'AMGN', 'BILL', 'OLED', 'PEP', 'BTU', 'AEO', 'AMBA', 'C', 'XHB', 'AMG', 'IWM', 'ARKK', 'WDC', 'LNG', 'XOM', 'TEAM', 'UBER', 'CCI')\n",
      "Data Download Incomplete for 0: []\n",
      "Data Download Successful for 20: ['AFL', 'BLK', 'DIA', 'V', 'TSLA', 'BABA', 'ADSK', 'VXX', 'OIH', 'VLO', 'PINS', 'SQQQ', 'BNTX', 'ABNB', 'RKT', 'ILMN', 'ZBH', 'CLX', 'SOXL', 'DOCU']\n",
      "('AFL', 'BLK', 'DIA', 'V', 'TSLA', 'BABA', 'ADSK', 'VXX', 'OIH', 'VLO', 'PINS', 'SQQQ', 'BNTX', 'ABNB', 'RKT', 'ILMN', 'ZBH', 'CLX', 'SOXL', 'DOCU')\n",
      "Data Download Incomplete for 0: []\n",
      "Data Download Successful for 20: ['ACN', 'ALB', 'CCL', 'APO', 'CAT', 'SLB', 'TM', 'TOL', 'AAPL', 'INTU', 'BIIB', 'FSLR', 'TNDM', 'PYPL', 'BURL', 'GD', 'UNP', 'XLE', 'QQQ', 'AMD']\n",
      "('ACN', 'ALB', 'CCL', 'APO', 'CAT', 'SLB', 'TM', 'TOL', 'AAPL', 'INTU', 'BIIB', 'FSLR', 'TNDM', 'PYPL', 'BURL', 'GD', 'UNP', 'XLE', 'QQQ', 'AMD')\n"
     ]
    }
   ],
   "source": [
    "# Start main function\n",
    "main(securities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
